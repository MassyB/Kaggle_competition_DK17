{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\", sep=\";\")\n",
    "test_df = pd.read_csv(\"test.csv\", sep=\";\", header=None, names=train_df.columns.values)\n",
    "\n",
    "# get all the data\n",
    "all_data_df = train_df.append(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## cleaning the data, get rid of the NaN values in some \n",
    "for column_to_cure in [\"job\", \"marital\", \"education\", \"loan\", \"housing\", \"default\"]:\n",
    "    most_commun = all_data_df[column_to_cure].mode().iloc[0]\n",
    "    all_data_df[column_to_cure].replace(\"unknown\", most_commun, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## encode the target value\n",
    "all_data_df['y'].replace(\"yes\", 1.0, inplace=True)\n",
    "all_data_df['y'].replace(\"no\", 0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## drop the default column (there is only one yes among all data points)\n",
    "all_data_df.drop([\"default\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Adding features\n",
    "## using one-hot-encoding on all the categorical columns except the y which is the target\n",
    "categorical_columns = list(all_data_df.dtypes[all_data_df.dtypes == \"object\"].index.values)\n",
    "all_data_df = pd.get_dummies(all_data_df, columns=categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4119, 56)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                                int64\n",
       "duration                           int64\n",
       "campaign                           int64\n",
       "pdays                              int64\n",
       "previous                           int64\n",
       "emp.var.rate                     float64\n",
       "cons.price.idx                   float64\n",
       "cons.conf.idx                    float64\n",
       "euribor3m                        float64\n",
       "nr.employed                      float64\n",
       "y                                float64\n",
       "job_admin.                       float64\n",
       "job_blue-collar                  float64\n",
       "job_entrepreneur                 float64\n",
       "job_housemaid                    float64\n",
       "job_management                   float64\n",
       "job_retired                      float64\n",
       "job_self-employed                float64\n",
       "job_services                     float64\n",
       "job_student                      float64\n",
       "job_technician                   float64\n",
       "job_unemployed                   float64\n",
       "marital_divorced                 float64\n",
       "marital_married                  float64\n",
       "marital_single                   float64\n",
       "education_basic.4y               float64\n",
       "education_basic.6y               float64\n",
       "education_basic.9y               float64\n",
       "education_high.school            float64\n",
       "education_illiterate             float64\n",
       "education_professional.course    float64\n",
       "education_university.degree      float64\n",
       "housing_no                       float64\n",
       "housing_yes                      float64\n",
       "loan_no                          float64\n",
       "loan_yes                         float64\n",
       "contact_cellular                 float64\n",
       "contact_telephone                float64\n",
       "month_apr                        float64\n",
       "month_aug                        float64\n",
       "month_dec                        float64\n",
       "month_jul                        float64\n",
       "month_jun                        float64\n",
       "month_mar                        float64\n",
       "month_may                        float64\n",
       "month_nov                        float64\n",
       "month_oct                        float64\n",
       "month_sep                        float64\n",
       "day_of_week_fri                  float64\n",
       "day_of_week_mon                  float64\n",
       "day_of_week_thu                  float64\n",
       "day_of_week_tue                  float64\n",
       "day_of_week_wed                  float64\n",
       "poutcome_failure                 float64\n",
       "poutcome_nonexistent             float64\n",
       "poutcome_success                 float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## get the Kaggle train and test dataset\n",
    "test_df = all_data_df[all_data_df['y'].isnull()]\n",
    "train_df= all_data_df[all_data_df['y'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## getting the numpy equivalent \n",
    "y = train_df['y'].values\n",
    "X = train_df.loc[:, train_df.columns != 'y'].values\n",
    "X_Kaggle = test_df.loc[:, test_df.columns != 'y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2999, 55)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1120, 55)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Kaggle.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using piplines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.feature_selection import RFE, SelectPercentile\n",
    "#classifiers\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# grid_search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer,  matthews_corrcoef\n",
    "# imbalanced data\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from imblearn.under_sampling import EditedNearestNeighbours, TomekLinks, RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "\n",
    "r_state = 0\n",
    "n_folds = 3\n",
    "mcc = make_scorer(matthews_corrcoef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the scaler\n",
    "minMax_scaler = MinMaxScaler()\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "# the feature_selector\n",
    "RFE_transformer = RFE(DecisionTreeClassifier(random_state=r_state) )\n",
    "select_percentile_transformer = SelectPercentile()\n",
    "\n",
    "# the feature transformer \n",
    "polynomial_transformer = PolynomialFeatures()\n",
    "\n",
    "# the samplers\n",
    "## over_samplers \n",
    "smote_sampler = SMOTE(random_state= r_state)\n",
    "\n",
    "## under samplers\n",
    "enn_sampler = EditedNearestNeighbours(random_state=r_state)\n",
    "tomek_links_sampler = TomekLinks(random_state=r_state)\n",
    "random_under_sampler = RandomUnderSampler(random_state= r_state)\n",
    "\n",
    "# the estimator\n",
    "rf = RandomForestClassifier(random_state=r_state)\n",
    "adaBoost  = AdaBoostClassifier(random_state= r_state)\n",
    "svc = SVC(random_state= r_state)\n",
    "log_reg = LogisticRegression(random_state= r_state)\n",
    "mlp = MLPClassifier(random_state=r_state)\n",
    "gboost = GradientBoostingClassifier(random_state= r_state)\n",
    "\n",
    "# balanced bagging classifier\n",
    "balanced_bagging_classfier = BalancedBaggingClassifier(random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neural_net_pipline = Pipeline([('scaler', minMax_scaler), \n",
    "                            ('feature_extractor', RFE_transformer),\n",
    "                            ('over_sampling', smote_sampler),\n",
    "                            ('under_sampling', enn_sampler),\n",
    "                            ('estimator', mlp)])\n",
    "\n",
    "neural_net_grid = [\n",
    "    {'scaler': [minMax_scaler, standart_scaler],\n",
    "     'feature_extractor':[RFE_transformer],\n",
    "     'feature_extractor__n_features_to_select':[X.shape[1] // 5, X.shape[1] // 3, X.shape[1] // 2 ],\n",
    "     'over_sampling__kind': ['svm', 'borderline1', 'borderline2'],\n",
    "     'under_sampling':[enn_sampler, tomek_links_sampler]\n",
    "     },\n",
    "    {'scaler': [minMax_scaler, standart_scaler],\n",
    "     'feature_extractor':[select_percentile_transformer],\n",
    "     'feature_extractor__percentile':[10, 20, 30, 40, 50],\n",
    "     'over_sampling__kind': ['svm', 'borderline1', 'borderline2'],\n",
    "     'under_sampling':[enn_sampler, tomek_links_sampler]\n",
    "     }\n",
    "]\n",
    "\n",
    "neural_net = GridSearchCV(neural_net_pipline, neural_net_grid, scoring=mcc, cv= n_folds, n_jobs=1)\n",
    "neural_net.fit(X,y)\n",
    "neural_net.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55632645627343091"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_net.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## using grid search for logistic regression \n",
    "\n",
    "logreg_pipeline = Pipeline([('scaler', minMax_scaler), \n",
    "                            ('feature_extractor', RFE_transformer),\n",
    "                            ('over_sampling', smote_sampler),\n",
    "                            ('under_sampling', enn_sampler),\n",
    "                            ('feature_interraction', polynomial_transformer),\n",
    "                            ('estimator', log_reg)])\n",
    "\n",
    "## set a grid search\n",
    "logreg_grid = [         {'scaler': [minMax_scaler],\n",
    "                         'feature_extractor__n_features_to_select':[X.shape[1] // 3],\n",
    "                        'over_sampling': [smote_sampler],\n",
    "                        'over_sampling__kind': ['svm','borderline1','borderline2'],\n",
    "                        'under_sampling': [enn_sampler, tomek_links_sampler],\n",
    "                        'feature_interraction': [polynomial_transformer],\n",
    "                        'feature_interraction__degree': [1,2,3],\n",
    "                        'estimator': [log_reg],\n",
    "                        'estimator__C':[0.01,0.1,1,10,100]},\n",
    "                        ## second grid search\n",
    "                         {'over_sampling': [None],\n",
    "                        'feature_extractor__n_features_to_select':[X.shape[1] // 3],\n",
    "                        'under_sampling': [None],\n",
    "                        'feature_interraction':[polynomial_transformer],\n",
    "                        'feature_interraction__degree':[1,2,3],\n",
    "                        'estimator__C':[0.01,0.1,1,10,100],\n",
    "                        'estimator__class_weight':['balanced']}]\n",
    "\n",
    "logreg = GridSearchCV(logreg_pipeline, logreg_grid, cv=n_folds, scoring=mcc, n_jobs=-1)\n",
    "logreg.fit(X,y)\n",
    "logreg.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator': LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       " 'estimator__C': 100,\n",
       " 'feature_interraction': PolynomialFeatures(degree=1, include_bias=True, interaction_only=False),\n",
       " 'feature_interraction__degree': 1,\n",
       " 'over_sampling': SMOTE(k=None, k_neighbors=5, kind='svm', m=None, m_neighbors=10, n_jobs=1,\n",
       "    out_step=0.5, random_state=0, ratio='auto', svm_estimator=None),\n",
       " 'over_sampling__kind': 'svm',\n",
       " 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1)),\n",
       " 'under_sampling': TomekLinks(n_jobs=1, random_state=0, ratio='auto', return_indices=False)}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55368330616345285"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid search for linear svm\n",
    "svm_pipeline = Pipeline([('scaler', minMax_scaler), \n",
    "                         ('feature_extractor', RFE_transformer),\n",
    "                         ('over_sampling', smote_sampler),\n",
    "                         ('under_sampling', enn_sampler),\n",
    "                         ('feature_interraction', polynomial_transformer),\n",
    "                         ('estimator', svc)])\n",
    "\n",
    "## set a grid search\n",
    "svm_grid = [            {'over_sampling__kind': ['svm','borderline1','borderline2'],\n",
    "                        'under_sampling': [enn_sampler, tomek_links_sampler],\n",
    "                        'feature_interraction__degree': [1,2,3],\n",
    "                        'estimator__C': [0.01,0.1,1,10,100],\n",
    "                        'estimator__kernel': ['linear'],\n",
    "                         'feature_extractor__n_features_to_select':[X.shape[1] // 3],\n",
    "                        },\n",
    "                        ## second grid search\n",
    "                        {'over_sampling': [None],\n",
    "                        'under_sampling': [None],\n",
    "                        'feature_extractor__n_features_to_select':[X.shape[1] // 3],\n",
    "                        'feature_interraction__degree':[1,2,3],\n",
    "                        'estimator__C':[0.01,0.1,1,10,100],\n",
    "                        'estimator__kernel': ['linear'],\n",
    "                        'estimator__class_weight':['balanced']}\n",
    "           ]\n",
    "\n",
    "svmlinear = GridSearchCV(svm_pipeline, svm_grid, cv= n_folds, scoring=mcc, n_jobs=-1)\n",
    "svmlinear.fit(X,y)\n",
    "svmlinear.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__C': 10,\n",
       " 'estimator__kernel': 'linear',\n",
       " 'feature_interraction__degree': 1,\n",
       " 'over_sampling__kind': 'svm',\n",
       " 'under_sampling': TomekLinks(n_jobs=1, random_state=0, ratio='auto', return_indices=False)}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmlinear.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Support Vector Machine models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55330785341998578"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we do not include polynomial features\n",
    "\n",
    "svm_nonlinear_pipeline= Pipeline([('scaler', minMax_scaler), \n",
    "                         ('feature_extractor', RFE_transformer),\n",
    "                         ('over_sampling', smote_sampler),\n",
    "                         ('under_sampling', enn_sampler),\n",
    "                         ('estimator', svc)])\n",
    "svm_nonlinear_grid =[\n",
    "    {'over_sampling__kind': ['svm','borderline1', 'borderline2'],\n",
    "     'feature_extractor__n_features_to_select':[X.shape[1] // 3],\n",
    "     'under_sampling':[enn_sampler, tomek_links_sampler],\n",
    "     'estimator__kernel':['rbf'],\n",
    "     'estimator__C':[0.01, 0.1, 1, 10, 100],\n",
    "     'estimator__gamma':[0.01, 0.1, 1, 10, 100]}\n",
    "]\n",
    "\n",
    "svm_nonlinear = GridSearchCV(svm_nonlinear_pipeline, svm_nonlinear_grid, cv=n_folds, scoring = mcc, n_jobs=-1)\n",
    "svm_nonlinear.fit(X,y)\n",
    "svm_nonlinear.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__C': 100,\n",
       " 'estimator__gamma': 0.01,\n",
       " 'estimator__kernel': 'rbf',\n",
       " 'over_sampling__kind': 'borderline2',\n",
       " 'under_sampling': TomekLinks(n_jobs=1, random_state=0, ratio='auto', return_indices=False)}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_nonlinear.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Methodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57668378986939639"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest (no scaling here, it's not needed)\n",
    "\n",
    "rf_pipline = Pipeline([ ('feature_extractor', RFE_transformer),\n",
    "                         ('over_sampling', smote_sampler),\n",
    "                         ('under_sampling', enn_sampler),\n",
    "                         ('estimator', rf)])\n",
    "\n",
    "rf_gride = [\n",
    "    {'over_sampling__kind': ['svm'],\n",
    "     'under_sampling':[tomek_links_sampler],\n",
    "     'feature_extractor__n_features_to_select':[6,11,15],\n",
    "     'estimator__n_estimators': [20, 40, 60],\n",
    "     'estimator__max_features':[0.5, 1.0],\n",
    "     'estimator__max_depth':[5,10]\n",
    "     }\n",
    "]\n",
    "\n",
    "random_forest = GridSearchCV(rf_pipline, rf_gride, cv=n_folds, scoring=mcc, n_jobs=-1)\n",
    "random_forest.fit(X,y)\n",
    "random_forest.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__max_depth': 5,\n",
       " 'estimator__max_features': 0.5,\n",
       " 'estimator__n_estimators': 40,\n",
       " 'feature_extractor__n_features_to_select': 11,\n",
       " 'over_sampling__kind': 'svm',\n",
       " 'under_sampling': TomekLinks(n_jobs=1, random_state=0, ratio='auto', return_indices=False)}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest.best_params_\n",
    "# try to add 0.2 for max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5537669231060447"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adda boost \n",
    "ada_pipline = Pipeline([ ('feature_extractor', RFE_transformer),\n",
    "                         ('over_sampling', smote_sampler),\n",
    "                         ('under_sampling', enn_sampler),\n",
    "                         ('estimator', adaBoost)])\n",
    "ada_grid = [\n",
    "    {\n",
    "     'over_sampling__kind': ['svm'],\n",
    "     'under_sampling':[tomek_links_sampler],\n",
    "     'feature_extractor__n_features_to_select':[8,11, 13],\n",
    "     'estimator__base_estimator': [DecisionTreeClassifier(max_depth=5), DecisionTreeClassifier(max_depth=10)],\n",
    "     'estimator__algorithm':['SAMME', 'SAMME.R'],\n",
    "     'estimator__learning_rate':[1, 0.8]\n",
    "     }\n",
    "]\n",
    "\n",
    "\n",
    "ada = GridSearchCV(ada_pipline, ada_grid, cv=n_folds, scoring=mcc, n_jobs=-1)\n",
    "ada.fit(X,y)\n",
    "ada.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__algorithm': 'SAMME.R',\n",
       " 'estimator__base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "             splitter='best'),\n",
       " 'estimator__learning_rate': 0.8,\n",
       " 'feature_extractor__n_features_to_select': 11,\n",
       " 'over_sampling__kind': 'svm',\n",
       " 'under_sampling': TomekLinks(n_jobs=1, random_state=0, ratio='auto', return_indices=False)}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59628181717552442"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## GradientBoostingClassifier\n",
    "g_boost_pipeline = Pipeline([('feature_extractor', RFE_transformer),\n",
    "                             ('scaler', minMax_scaler),\n",
    "                             ('over_sampling', smote_sampler),\n",
    "                             ('under_sampling', enn_sampler),\n",
    "                             ('estimator', gboost)])\n",
    "\n",
    "g_boost_grid = [\n",
    "    {\n",
    "     'scaler': [minMax_scaler],\n",
    "     'over_sampling__kind': ['svm'],\n",
    "     'under_sampling':[tomek_links_sampler],\n",
    "     'feature_extractor__n_features_to_select':[12,13,14],\n",
    "     'estimator__loss': ['exponential'],\n",
    "     'estimator__n_estimators':[100, 150],\n",
    "     'estimator__max_depth':[2,3,4],\n",
    "     'estimator__subsample':[.66, 0.5],\n",
    "     'estimator__max_features':[.8, .9],\n",
    "     }\n",
    "]\n",
    "\n",
    "\n",
    "g_boost = GridSearchCV(g_boost_pipeline, g_boost_grid, cv=n_folds, scoring=mcc, n_jobs=-1)\n",
    "g_boost.fit(X,y)\n",
    "g_boost.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__loss': 'exponential',\n",
       " 'estimator__max_depth': 3,\n",
       " 'estimator__max_features': 0.8,\n",
       " 'estimator__n_estimators': 100,\n",
       " 'estimator__subsample': 0.66,\n",
       " 'feature_extractor__n_features_to_select': 13,\n",
       " 'over_sampling__kind': 'svm',\n",
       " 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1)),\n",
       " 'under_sampling': TomekLinks(n_jobs=1, random_state=0, ratio='auto', return_indices=False)}"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_boost.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__loss': 'exponential',\n",
       " 'estimator__max_depth': 3,\n",
       " 'estimator__max_features': 0.8,\n",
       " 'estimator__n_estimators': 100,\n",
       " 'estimator__subsample': 0.66,\n",
       " 'feature_extractor__n_features_to_select': 13,\n",
       " 'over_sampling__kind': 'svm',\n",
       " 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1)),\n",
       " 'under_sampling': TomekLinks(n_jobs=1, random_state=0, ratio='auto', return_indices=False)}"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_boost.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### balanced bagging classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 2668, 1.0: 331})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54256414529987329"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_pipeline = Pipeline([ ('feature_extractor', RFE_transformer),\n",
    "                              ('estimator',balanced_bagging_classfier)])\n",
    "bagging_grid = [{\n",
    "        'feature_extractor__n_features_to_select':[11, 13, 15, 17],\n",
    "        'estimator__base_estimator':[DecisionTreeClassifier(max_depth=5)],\n",
    "        'estimator__n_estimators':[80],\n",
    "        'estimator__max_samples': [.66],\n",
    "        'estimator__max_features': [.66, 1],\n",
    "        'estimator__bootstrap': [True],\n",
    "        'estimator__replacement':[True, False],\n",
    "        'estimator__oob_score': [True]\n",
    "    }]\n",
    "\n",
    "bagging = GridSearchCV(bagging_pipeline, bagging_grid, cv= n_folds, scoring=mcc, n_jobs=-1)\n",
    "bagging.fit(X,y)\n",
    "bagging.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BalancedBaggingClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "             splitter='best'),\n",
       " 'estimator__bootstrap': True,\n",
       " 'estimator__max_features': 0.66,\n",
       " 'estimator__max_samples': 0.66,\n",
       " 'estimator__n_estimators': 80,\n",
       " 'estimator__oob_score': True,\n",
       " 'estimator__replacement': False,\n",
       " 'feature_extractor__n_features_to_select': 11}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test with Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kaggle_df = pd.read_csv(\"test_kaggle.csv\", sep=\",\")\n",
    "kaggle_df['y'].replace(\"yes\", 1.0, inplace=True)\n",
    "kaggle_df['y'].replace(\"no\", 0.0, inplace=True)\n",
    "y_kaggle = kaggle_df['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_kaggle.shape[0] == X_Kaggle.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59730759260684463"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matthews_corrcoef(y_pred=g_boost.predict(X_Kaggle), y_true= y_kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'predict_gboost_0_597307592607'"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name= \"predict_gboost_\"+str(matthews_corrcoef(y_pred=g_boost.predict(X_Kaggle), y_true= y_kaggle))\n",
    "file_name = file_name.replace('.','_')\n",
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_submission(file_name, y_test):\n",
    "    y_test=y_test.astype(np.int64)\n",
    "    submission_df = pd.DataFrame({\"Id\": range(1, len(y_test) + 1),\n",
    "                                  \"prediction\": y_test})\n",
    "    submission_df.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_submission(file_name, g_boost.predict(X_Kaggle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:kaggle_ml]",
   "language": "python",
   "name": "conda-env-kaggle_ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
